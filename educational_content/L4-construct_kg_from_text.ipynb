{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b83f29-aaac-48c5-96d0-c7306a4829c4",
   "metadata": {},
   "source": [
    "# Lesson 4: Constructing a Knowledge Graph from Text Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f162a-036e-4f92-b747-7ccfc6dc7b70",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fd4a6180; padding:15px; margin-left:20px\"> <b>Note:</b> This notebook takes about 30 seconds to be ready to use. Please wait until the \"Kernel starting, please wait...\" message clears from the top of the notebook before running any cells. You may start the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbf000-c1dc-4859-bf14-cbc84eb32053",
   "metadata": {},
   "source": [
    "### Import packages and set up Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8570032f-9008-4d8a-8232-59866218e01e",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_classic.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4edcf01-cac6-4539-a8c3-db5b175a41b2",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "# OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "# Note the code below is unique to this course environment, and not a \n",
    "# standard part of Neo4j's integration with OpenAI. Remove if running \n",
    "# in your own environment.\n",
    "# OPENAI_ENDPOINT = os.getenv('OPENAI_BASE_URL') + '/embeddings'\n",
    "\n",
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c6cb6-74ba-4d94-81d2-9bca5893c44a",
   "metadata": {},
   "source": [
    "### Take a look at a Form 10-K json file\n",
    "\n",
    "- Publicly traded companies are required to fill a form 10-K each year with the Securities and Exchange Commision (SEC)\n",
    "- You can search these filings using the SEC's [EDGAR database](https://www.sec.gov/edgar/search/)\n",
    "- For the next few lessons, you'll work with a single 10-K form for a company called [NetApp](https://www.netapp.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29dc84a-a51d-4f48-8dae-6c9c39565299",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "first_file_name = \"./data/form10k/0000950170-23-027948.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6697f-e8f1-4e1a-aa6d-0d641fbc3649",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "first_file_as_object = json.load(open(first_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ef32c-6f10-430c-83b4-f34e54fb45d8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "type(first_file_as_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd1c0f-bca0-4f16-846a-8158967b61e8",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "for k,v in first_file_as_object.items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431a995-84c6-40ee-854f-8f09d7e43259",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text = first_file_as_object['item1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee07cd1-00c4-477b-9f05-5f0db5cef432",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text[0:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3d09a3-25a2-4f92-b9cb-37a6c0e4c808",
   "metadata": {},
   "source": [
    "### Split Form 10-K sections into chunks\n",
    "- Set up text splitter using LangChain\n",
    "- For now, split only the text from the \"item 1\" section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e4843-686a-40f1-97d1-b4811084d1b1",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbbf0b-6d25-46ab-9539-fb38479ff4fe",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text_chunks = text_splitter.split_text(item1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35dc351-48d7-4487-b311-7224eb880c68",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "type(item1_text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc769d72-c01c-4d7b-aa3f-b12e8acd99e6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "len(item1_text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af610b46-68f3-4763-9ffb-eb452dc61acf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf6522-52e3-441f-b0c3-c43d754ba55a",
   "metadata": {},
   "source": [
    "- Set up helper function to chunk all sections of the Form 10-K\n",
    "- You'll limit the number of chunks in each section to 20 to speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5ec07-a825-4e87-8e30-f09efa586a12",
   "metadata": {
    "height": 489
   },
   "outputs": [],
   "source": [
    "def split_form10k_data_from_file(file):\n",
    "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
    "    file_as_object = json.load(open(file)) # open the json file\n",
    "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
    "        print(f'Processing {item} from {file}') \n",
    "        item_text = file_as_object[item] # grab the text of the item\n",
    "        item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
    "        chunk_seq_id = 0\n",
    "        for chunk in item_text_chunks[:20]: # only take the first 20 chunks\n",
    "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
    "            # finally, construct a record with metadata and the chunk text\n",
    "            chunks_with_metadata.append({\n",
    "                'text': chunk, \n",
    "                # metadata from looping...\n",
    "                'f10kItem': item,\n",
    "                'chunkSeqId': chunk_seq_id,\n",
    "                # constructed metadata...\n",
    "                'formId': f'{form_id}', # pulled from the filename\n",
    "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
    "                # metadata from file...\n",
    "                'names': file_as_object['names'],\n",
    "                'cik': file_as_object['cik'],\n",
    "                'cusip6': file_as_object['cusip6'],\n",
    "                'source': file_as_object['source'],\n",
    "            })\n",
    "            chunk_seq_id += 1\n",
    "        print(f'\\tSplit into {chunk_seq_id} chunks')\n",
    "    return chunks_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696ea15-abf7-4f05-8fd2-8e91e5fc540c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "first_file_chunks = split_form10k_data_from_file(first_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b42f97-911f-495d-8176-a10879d2aae1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "first_file_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58952e6c-7e9c-44eb-b52b-bb11245738a4",
   "metadata": {},
   "source": [
    "### Create graph nodes using text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968783b2-5c17-46cc-abfd-b6b5dfffe3bb",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.names = $chunkParam.names,\n",
    "        mergedChunk.formId = $chunkParam.formId, \n",
    "        mergedChunk.cik = $chunkParam.cik, \n",
    "        mergedChunk.cusip6 = $chunkParam.cusip6, \n",
    "        mergedChunk.source = $chunkParam.source, \n",
    "        mergedChunk.f10kItem = $chunkParam.f10kItem, \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        mergedChunk.text = $chunkParam.text\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efd2c9-ad31-440a-92c5-9394465950f9",
   "metadata": {},
   "source": [
    "- Set up connection to graph instance using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f43dab-155e-4172-959b-e05968c0c6a8",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to retrieve routing information\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not connect to Neo4j database. Please ensure that the url is correct",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mExceptionGroup\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mExceptionGroup\u001b[39m: All routing table requests failed (1 sub-exception)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/langchain_community/graphs/neo4j_graph.py:415\u001b[39m, in \u001b[36mNeo4jGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify_connectivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ServiceUnavailable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/neo4j/_sync/driver.py:1060\u001b[39m, in \u001b[36mDriver.verify_connectivity\u001b[39m\u001b[34m(self, **config)\u001b[39m\n\u001b[32m   1059\u001b[39m session_config = \u001b[38;5;28mself\u001b[39m._read_session_config(config)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/neo4j/_sync/driver.py:1289\u001b[39m, in \u001b[36mDriver._get_server_info\u001b[39m\u001b[34m(self, session_config)\u001b[39m\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._session(session_config) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/neo4j/_sync/work/session.py:173\u001b[39m, in \u001b[36mSession._get_server_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mREAD_ACCESS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munprepared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m server_info = \u001b[38;5;28mself\u001b[39m._connection.server_info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/neo4j/_sync/work/session.py:126\u001b[39m, in \u001b[36mSession._connect\u001b[39m\u001b[34m(self, access_mode, **acquire_kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/neo4j/_sync/work/workspace.py:166\u001b[39m, in \u001b[36mWorkspace._connect\u001b[39m\u001b[34m(self, access_mode, auth, **acquire_kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m ssr_enabled = \u001b[38;5;28mself\u001b[39m._pool.ssr_enabled\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m target_db = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_routing_target_database\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43macquire_auth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssr_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssr_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43macquisition_deadline\u001b[49m\u001b[43m=\u001b[49m\u001b[43macquisition_deadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m acquire_kwargs_ = {\n\u001b[32m    172\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maccess_mode\u001b[39m\u001b[33m\"\u001b[39m: access_mode,\n\u001b[32m    173\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: acquisition_deadline,\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdatabase_callback\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._make_db_resolution_callback(),\n\u001b[32m    179\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/neo4j/_sync/work/workspace.py:244\u001b[39m, in \u001b[36mWorkspace._get_routing_target_database\u001b[39m\u001b[34m(self, acquire_auth, ssr_enabled, acquisition_deadline)\u001b[39m\n\u001b[32m    243\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#0000]  _: <WORKSPACE> resolve home database\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_routing_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimp_user\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_bookmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43macquire_auth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43macquisition_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43macquisition_deadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_db_resolution_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m AcquisitionDatabase(\u001b[38;5;28mself\u001b[39m._config.database)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/neo4j/_sync/io/_pool.py:1076\u001b[39m, in \u001b[36mNeo4jPool.update_routing_table\u001b[39m\u001b[34m(self, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback)\u001b[39m\n\u001b[32m   1075\u001b[39m         e = error\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[32m   1077\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUnable to retrieve routing information\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1078\u001b[39m ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mServiceUnavailable\u001b[39m: Unable to retrieve routing information",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m kg = \u001b[43mNeo4jGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEO4J_URI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musername\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEO4J_USERNAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEO4J_PASSWORD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEO4J_DATABASE\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:221\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    219\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    220\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Learnings/AI/Coursera/KnowledgeGraphRAG/.venv/lib/python3.13/site-packages/langchain_community/graphs/neo4j_graph.py:417\u001b[39m, in \u001b[36mNeo4jGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28mself\u001b[39m._driver.verify_connectivity()\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ServiceUnavailable:\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    418\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Neo4j database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the url is correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    420\u001b[39m     )\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.AuthError:\n\u001b[32m    422\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    423\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Neo4j database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the username and password are correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    425\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Could not connect to Neo4j database. Please ensure that the url is correct"
     ]
    }
   ],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb150bf-1f77-4a5b-be0d-23ab86e32385",
   "metadata": {},
   "source": [
    "- Create a single chunk node for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdc4a7-8fb9-4cd9-8a79-8066ad67f618",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "kg.query(merge_chunk_node_query, \n",
    "         params={'chunkParam':first_file_chunks[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b368dd5-6e50-46db-b500-29993895631e",
   "metadata": {},
   "source": [
    "- Create a uniqueness constraint to avoid duplicate chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8269f83-eb19-4a3f-979c-8b41b1e9f750",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e207e5f-eb17-452c-9c65-4846d3bbf840",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c465e-c43f-422d-a3a1-17705a1019d5",
   "metadata": {},
   "source": [
    "- Loop through and create nodes for all chunks\n",
    "- Should create 23 nodes because you set a limit of 20 chunks in the text splitting function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4f598-a6b8-419f-b247-4eecd1f3d98a",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "node_count = 0\n",
    "for chunk in first_file_chunks:\n",
    "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkId']}\")\n",
    "    kg.query(merge_chunk_node_query, \n",
    "            params={\n",
    "                'chunkParam': chunk\n",
    "            })\n",
    "    node_count += 1\n",
    "print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d820104-51be-4709-b531-2bdc9b6d5eec",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (n)\n",
    "         RETURN count(n) as nodeCount\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b6bfa-9e07-4963-9b3f-50cdba4468bc",
   "metadata": {},
   "source": [
    "### Create a vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79355493-3790-4b05-898b-a3eaaea87155",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.textEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b42c0-a90c-4f97-8c8a-b8a4ec70f9d1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e379f-69d1-41de-8443-c6f5660603ab",
   "metadata": {},
   "source": [
    "### Calculate embedding vectors for chunks and populate index\n",
    "- This query calculates the embedding vector and stores it as a property called `textEmbedding` on each `Chunk` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f2d4f2-ea0b-4731-8b29-a858e05f5b36",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "    WITH chunk, genai.vector.encode(\n",
    "      chunk.text, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey, \n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS vector\n",
    "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "    \"\"\", \n",
    "    params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59550c1c-5d7f-4e87-b5fc-ae7a4edb3731",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5286ca-106c-49ec-8f60-f142db8bb680",
   "metadata": {},
   "source": [
    "### Use similarity search to find relevant chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab0d7b-7be2-4a2b-8b2c-2ea8a35350bd",
   "metadata": {},
   "source": [
    "- Setup a help function to perform similarity search using the vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50153721-d565-47ac-b288-d8b9798d9479",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "def neo4j_vector_search(question):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  vector_search_query = \"\"\"\n",
    "    WITH genai.vector.encode(\n",
    "      $question, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey,\n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS question_embedding\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
    "    RETURN score, node.text AS text\n",
    "  \"\"\"\n",
    "  similar = kg.query(vector_search_query, \n",
    "                     params={\n",
    "                      'question': question, \n",
    "                      'openAiApiKey':OPENAI_API_KEY,\n",
    "                      'openAiEndpoint': OPENAI_ENDPOINT,\n",
    "                      'index_name':VECTOR_INDEX_NAME, \n",
    "                      'top_k': 10})\n",
    "  return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0f292-59e8-432c-b521-2a77613b08c6",
   "metadata": {},
   "source": [
    "- Ask a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9975a-d26f-4477-92ac-8dcfb3119c47",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "search_results = neo4j_vector_search(\n",
    "    'In a single sentence, tell me about Netapp.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2370fb5-9990-42e3-9ac2-0edf03969705",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "search_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777c9ea-ca26-4690-8487-6aec06db1d4c",
   "metadata": {},
   "source": [
    "### Set up a LangChain RAG workflow to chat with the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cdab04-4db1-4776-bd89-f4f87b57bde4",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    node_label=VECTOR_NODE_LABEL,\n",
    "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7abbd6-bf4e-4fc3-9c20-c4246ed3ec4e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "retriever = neo4j_vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38dd23-fa0f-4304-849a-80043e34a1e7",
   "metadata": {},
   "source": [
    "- Set up a RetrievalQAWithSourcesChain to carry out question answering\n",
    "- You can check out the LangChain documentation for this chain [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b45848-112f-4e4f-9c76-cf2bda9c6f8e",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aee157-c777-4c9a-949b-c55005d19c41",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def prettychain(question: str) -> str:\n",
    "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
    "    response = chain({\"question\": question},\n",
    "        return_only_outputs=True,)\n",
    "    print(textwrap.fill(response['answer'], 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb96301-66a2-47e9-87a7-13d926f85019",
   "metadata": {},
   "source": [
    "- Ask a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b234d29-7fc0-483f-bbfa-459617be96c1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "question = \"What is Netapp's primary business?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2228aa-2af0-44cd-99b0-bffdc72de62b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prettychain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa5b5b-5ec6-4903-bb53-acf8bd5f49c3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prettychain(\"Where is Netapp headquartered?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bdd8e-90ca-4267-aef2-db33b28937b6",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Netapp. \n",
    "    Limit your answer to a single sentence.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10715705-25a7-4c21-88e2-bc540c72dacb",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Apple. \n",
    "    Limit your answer to a single sentence.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53300764-c93b-4127-9bbd-9e17428d066c",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Apple. \n",
    "    Limit your answer to a single sentence.\n",
    "    If you are unsure about the answer, say you don't know.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab2124-77c4-496b-b951-44c9466fe941",
   "metadata": {},
   "source": [
    "### Ask you own question!\n",
    "- Add your own question to the call to prettychain below to find out more about NetApp\n",
    "- Here is NetApp's website if you want some inspiration: https://www.netapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238eaec-7080-4e45-80f0-5b37e2340387",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    ADD YOUR OWN QUESTION HERE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba6cf5",
   "metadata": {},
   "source": [
    "# Lesson 4: Constructing a Knowledge Graph from Text Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6dc926",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fd4a6180; padding:15px; margin-left:20px\"> <b>Note:</b> This notebook takes about 30 seconds to be ready to use. Please wait until the \"Kernel starting, please wait...\" message clears from the top of the notebook before running any cells. You may start the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ccfd08",
   "metadata": {},
   "source": [
    "### Import packages and set up Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb611b",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31816257",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "# Note the code below is unique to this course environment, and not a \n",
    "# standard part of Neo4j's integration with OpenAI. Remove if running \n",
    "# in your own environment.\n",
    "OPENAI_ENDPOINT = os.getenv('OPENAI_BASE_URL') + '/embeddings'\n",
    "\n",
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c56885",
   "metadata": {},
   "source": [
    "### Take a look at a Form 10-K json file\n",
    "\n",
    "- Publicly traded companies are required to fill a form 10-K each year with the Securities and Exchange Commision (SEC)\n",
    "- You can search these filings using the SEC's [EDGAR database](https://www.sec.gov/edgar/search/)\n",
    "- For the next few lessons, you'll work with a single 10-K form for a company called [NetApp](https://www.netapp.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa61631",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "first_file_name = \"./data/form10k/0000950170-23-027948.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1eb21e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "first_file_as_object = json.load(open(first_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d069b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "type(first_file_as_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207205a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "for k,v in first_file_as_object.items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb97db",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text = first_file_as_object['item1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3156eb1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text[0:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536568b1",
   "metadata": {},
   "source": [
    "### Split Form 10-K sections into chunks\n",
    "- Set up text splitter using LangChain\n",
    "- For now, split only the text from the \"item 1\" section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9467e",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f52b34",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text_chunks = text_splitter.split_text(item1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309d355",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "type(item1_text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c7346",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "len(item1_text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6290c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "item1_text_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a6ba1",
   "metadata": {},
   "source": [
    "- Set up helper function to chunk all sections of the Form 10-K\n",
    "- You'll limit the number of chunks in each section to 20 to speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437fda6",
   "metadata": {
    "height": 489
   },
   "outputs": [],
   "source": [
    "def split_form10k_data_from_file(file):\n",
    "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
    "    file_as_object = json.load(open(file)) # open the json file\n",
    "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
    "        print(f'Processing {item} from {file}') \n",
    "        item_text = file_as_object[item] # grab the text of the item\n",
    "        item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
    "        chunk_seq_id = 0\n",
    "        for chunk in item_text_chunks[:20]: # only take the first 20 chunks\n",
    "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
    "            # finally, construct a record with metadata and the chunk text\n",
    "            chunks_with_metadata.append({\n",
    "                'text': chunk, \n",
    "                # metadata from looping...\n",
    "                'f10kItem': item,\n",
    "                'chunkSeqId': chunk_seq_id,\n",
    "                # constructed metadata...\n",
    "                'formId': f'{form_id}', # pulled from the filename\n",
    "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
    "                # metadata from file...\n",
    "                'names': file_as_object['names'],\n",
    "                'cik': file_as_object['cik'],\n",
    "                'cusip6': file_as_object['cusip6'],\n",
    "                'source': file_as_object['source'],\n",
    "            })\n",
    "            chunk_seq_id += 1\n",
    "        print(f'\\tSplit into {chunk_seq_id} chunks')\n",
    "    return chunks_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b901de",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "first_file_chunks = split_form10k_data_from_file(first_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dfefa9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "first_file_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268202ea",
   "metadata": {},
   "source": [
    "### Create graph nodes using text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4b751",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.names = $chunkParam.names,\n",
    "        mergedChunk.formId = $chunkParam.formId, \n",
    "        mergedChunk.cik = $chunkParam.cik, \n",
    "        mergedChunk.cusip6 = $chunkParam.cusip6, \n",
    "        mergedChunk.source = $chunkParam.source, \n",
    "        mergedChunk.f10kItem = $chunkParam.f10kItem, \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        mergedChunk.text = $chunkParam.text\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe2e4f",
   "metadata": {},
   "source": [
    "- Set up connection to graph instance using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b48bb6",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7811a",
   "metadata": {},
   "source": [
    "- Create a single chunk node for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2dba5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "kg.query(merge_chunk_node_query, \n",
    "         params={'chunkParam':first_file_chunks[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523a824",
   "metadata": {},
   "source": [
    "- Create a uniqueness constraint to avoid duplicate chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4905ec4",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c066d6f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d6ece",
   "metadata": {},
   "source": [
    "- Loop through and create nodes for all chunks\n",
    "- Should create 23 nodes because you set a limit of 20 chunks in the text splitting function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75c7c9",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "node_count = 0\n",
    "for chunk in first_file_chunks:\n",
    "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkId']}\")\n",
    "    kg.query(merge_chunk_node_query, \n",
    "            params={\n",
    "                'chunkParam': chunk\n",
    "            })\n",
    "    node_count += 1\n",
    "print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec2218",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (n)\n",
    "         RETURN count(n) as nodeCount\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab5be1",
   "metadata": {},
   "source": [
    "### Create a vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03859a4e",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.textEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d303a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823da4db",
   "metadata": {},
   "source": [
    "### Calculate embedding vectors for chunks and populate index\n",
    "- This query calculates the embedding vector and stores it as a property called `textEmbedding` on each `Chunk` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d37833",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "    WITH chunk, genai.vector.encode(\n",
    "      chunk.text, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey, \n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS vector\n",
    "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "    \"\"\", \n",
    "    params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a013b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eda63c",
   "metadata": {},
   "source": [
    "### Use similarity search to find relevant chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e0074",
   "metadata": {},
   "source": [
    "- Setup a help function to perform similarity search using the vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3977f",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "def neo4j_vector_search(question):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  vector_search_query = \"\"\"\n",
    "    WITH genai.vector.encode(\n",
    "      $question, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey,\n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS question_embedding\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
    "    RETURN score, node.text AS text\n",
    "  \"\"\"\n",
    "  similar = kg.query(vector_search_query, \n",
    "                     params={\n",
    "                      'question': question, \n",
    "                      'openAiApiKey':OPENAI_API_KEY,\n",
    "                      'openAiEndpoint': OPENAI_ENDPOINT,\n",
    "                      'index_name':VECTOR_INDEX_NAME, \n",
    "                      'top_k': 10})\n",
    "  return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6eeba",
   "metadata": {},
   "source": [
    "- Ask a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda27ab",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "search_results = neo4j_vector_search(\n",
    "    'In a single sentence, tell me about Netapp.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124dc7af",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "search_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124c1e9",
   "metadata": {},
   "source": [
    "### Set up a LangChain RAG workflow to chat with the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90905933",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    node_label=VECTOR_NODE_LABEL,\n",
    "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d195c43",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "retriever = neo4j_vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074153e",
   "metadata": {},
   "source": [
    "- Set up a RetrievalQAWithSourcesChain to carry out question answering\n",
    "- You can check out the LangChain documentation for this chain [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f1533",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf00db",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def prettychain(question: str) -> str:\n",
    "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
    "    response = chain({\"question\": question},\n",
    "        return_only_outputs=True,)\n",
    "    print(textwrap.fill(response['answer'], 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a094f25",
   "metadata": {},
   "source": [
    "- Ask a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1dc09e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "question = \"What is Netapp's primary business?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6a6e7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prettychain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bd3df",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prettychain(\"Where is Netapp headquartered?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5463b",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Netapp. \n",
    "    Limit your answer to a single sentence.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd3ba3",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Apple. \n",
    "    Limit your answer to a single sentence.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a21de",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Apple. \n",
    "    Limit your answer to a single sentence.\n",
    "    If you are unsure about the answer, say you don't know.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a08cc",
   "metadata": {},
   "source": [
    "### Ask you own question!\n",
    "- Add your own question to the call to prettychain below to find out more about NetApp\n",
    "- Here is NetApp's website if you want some inspiration: https://www.netapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d28956",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    ADD YOUR OWN QUESTION HERE\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
